{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "#PySpark Practice Notebook"
      ],
      "metadata": {
        "id": "W6NeVZKBJR5G"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Source Data\n",
        "#Create a csv file for the following data\n",
        "product_id,product,country,sales\n",
        "1,Product A,USA,100\n",
        "2,Product B,USA,80\n",
        "3,Product C,USA,30\n",
        "1,Product A,Canada,60\n",
        "2,Product B,Canada,40\n",
        "4,Product D,UK,50\n",
        "5,Product E,UK,20\n",
        "1,Product A,Germany,70\n",
        "3,Product C,Germany,90\n",
        "4,Product D,Germany,40"
      ],
      "metadata": {
        "id": "PQ1dB4lsJRQZ",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 106
        },
        "outputId": "aa054837-e20b-4cc3-a22f-2eb89d8f0bf3"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "error",
          "ename": "SyntaxError",
          "evalue": "invalid syntax (<ipython-input-1-e808f6e1a47c>, line 4)",
          "traceback": [
            "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-1-e808f6e1a47c>\"\u001b[0;36m, line \u001b[0;32m4\u001b[0m\n\u001b[0;31m    1,Product A,USA,100\u001b[0m\n\u001b[0m              ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "53l5rX_YC8N8"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "z3H-jZd_I0xr",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cb9ad6cb-cfd5-4b3a-a31b-3b647de3227a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting pyspark\n",
            "  Downloading pyspark-3.5.1.tar.gz (317.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m317.0/317.0 MB\u001b[0m \u001b[31m2.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: py4j==0.10.9.7 in /usr/local/lib/python3.10/dist-packages (from pyspark) (0.10.9.7)\n",
            "Building wheels for collected packages: pyspark\n",
            "  Building wheel for pyspark (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pyspark: filename=pyspark-3.5.1-py2.py3-none-any.whl size=317488491 sha256=f8da46fbc8d2684b9f62c97042df47c52da5321a41c2e8483b9a836474b54ca7\n",
            "  Stored in directory: /root/.cache/pip/wheels/80/1d/60/2c256ed38dddce2fdd93be545214a63e02fbd8d74fb0b7f3a6\n",
            "Successfully built pyspark\n",
            "Installing collected packages: pyspark\n",
            "Successfully installed pyspark-3.5.1\n"
          ]
        }
      ],
      "source": [
        "#Import Pyspark & other necessary functions\n",
        "!pip install pyspark"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Create SparkSession for app \"Sales Data Analysis\"\n",
        "from pyspark.sql import SparkSession\n",
        "lti_spark = SparkSession.builder.appName('giri').getOrCreate()"
      ],
      "metadata": {
        "id": "ZFPi1eqMKFF7"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import csv\n",
        "data = [\n",
        "    [1,'Product A','USA',100],\n",
        "    [2,'Product B','USA',80],\n",
        "    [3,'Product C','USA',30],\n",
        "    [1,'Product A','Canada',60],\n",
        "    [2,'Product B','Canada',40],\n",
        "    [4,'Product D','UK',50],\n",
        "    [5,'Product E','UK',20],\n",
        "    [1,'Product A','Germany',70],\n",
        "    [3,'Product C','Germany',90],\n",
        "    [4,'Product D','Germany',40]\n",
        "]\n",
        "#file_name = 'sales_data.csv'\n",
        "#with open(file_name,'w',newline='') as csvfile:\n",
        "#  writer = csv.writer(csvfile)\n",
        "#  writer.writerows(data)\n",
        "# ['product_id','product','country','sales'],"
      ],
      "metadata": {
        "id": "yJHvA2RTHtkj"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df = lti_spark.createDataFrame(data,schema = ('product_id','product','country','sales'))\n",
        "df.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 158
        },
        "id": "ZloEQjFALUbx",
        "outputId": "3cbac148-338a-43aa-cfd8-01ab57b96ea9"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'lti_spark' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-3-39d694bd3211>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlti_spark\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcreateDataFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mschema\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m'product_id'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'product'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'country'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'sales'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'lti_spark' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df.write.csv('sales3.csv')"
      ],
      "metadata": {
        "id": "WZ3fGS9uNJSE"
      },
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Create a pyspark DataFrame from the csv file on local storage\n",
        "a= lti_spark.read.csv('sales2.csv')\n",
        "a.show()"
      ],
      "metadata": {
        "id": "kLiq1rcAJiV5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e1af9397-40e6-4ec3-ec9f-30d725b5e6c9"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+---+---------+-------+---+\n",
            "|_c0|      _c1|    _c2|_c3|\n",
            "+---+---------+-------+---+\n",
            "|  4|Product D|     UK| 50|\n",
            "|  5|Product E|     UK| 20|\n",
            "|  1|Product A|Germany| 70|\n",
            "|  3|Product C|Germany| 90|\n",
            "|  4|Product D|Germany| 40|\n",
            "|  1|Product A|    USA|100|\n",
            "|  2|Product B|    USA| 80|\n",
            "|  3|Product C|    USA| 30|\n",
            "|  1|Product A| Canada| 60|\n",
            "|  2|Product B| Canada| 40|\n",
            "+---+---------+-------+---+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Verify schema for the newly created file\n",
        "df.printSchema()"
      ],
      "metadata": {
        "id": "_fQfbu4_JiYf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7297148f-c712-471c-e8e5-ecd6276c0c0d"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "root\n",
            " |-- product_id: long (nullable = true)\n",
            " |-- product: string (nullable = true)\n",
            " |-- country: string (nullable = true)\n",
            " |-- sales: long (nullable = true)\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Display all entries for country \"Germany\"\n",
        "b = df.select('*').where(df.country == 'Germany')\n",
        "b.show()"
      ],
      "metadata": {
        "id": "U4k8qR1zJia2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0b5a5808-3bd8-4bd7-feaa-a41ec3f0fc5c"
      },
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+----------+---------+-------+-----+\n",
            "|product_id|  product|country|sales|\n",
            "+----------+---------+-------+-----+\n",
            "|         1|Product A|Germany|   70|\n",
            "|         3|Product C|Germany|   90|\n",
            "|         4|Product D|Germany|   40|\n",
            "+----------+---------+-------+-----+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Find the total number of products\n",
        "c = df.select(df.product).distinct().count()\n",
        "c"
      ],
      "metadata": {
        "id": "e5PRmHMuJ47W",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0a5612c9-1c4f-4d11-81d6-7727c77be98d"
      },
      "execution_count": 65,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "5"
            ]
          },
          "metadata": {},
          "execution_count": 65
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Find top 3 products\n",
        "d = df.sort(df.sales,ascending = False).limit(3)\n",
        "d.show()"
      ],
      "metadata": {
        "id": "fFz6bN_dJ49q",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3a3c266c-7ce5-42ce-c554-0e0c4f429fb0"
      },
      "execution_count": 67,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+----------+---------+-------+-----+\n",
            "|product_id|  product|country|sales|\n",
            "+----------+---------+-------+-----+\n",
            "|         1|Product A|    USA|  100|\n",
            "|         3|Product C|Germany|   90|\n",
            "|         2|Product B|    USA|   80|\n",
            "+----------+---------+-------+-----+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Calculate total sales\n",
        "q = df.agg({'sales':'sum'}).show()\n",
        "q"
      ],
      "metadata": {
        "id": "j4vyUsi2J5AR",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "41cfb265-88ca-47c1-b820-f1d8919fec18"
      },
      "execution_count": 70,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+----------+\n",
            "|sum(sales)|\n",
            "+----------+\n",
            "|       580|\n",
            "+----------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Find the market share of all products individually\n",
        "#from pyspark.sql.functions import udf\n",
        "b = df.groupBy(df.product).sum('sales')\n",
        "b.show()"
      ],
      "metadata": {
        "id": "WTxjxvceJ5Ct",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 193
        },
        "outputId": "14369d06-d2e2-4604-904b-28fd4f87d83c"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'df' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-2-3ad293b92c37>\u001b[0m in \u001b[0;36m<cell line: 3>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m#Find the market share of all products individually\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;31m#from pyspark.sql.functions import udf\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgroupBy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mproduct\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'sales'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'df' is not defined"
          ]
        }
      ]
    }
  ]
}